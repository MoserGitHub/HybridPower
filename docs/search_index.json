[["index.html", "Frequentist, Bayesian and hybrid approaches for sample size and power calculations Chapter 1 Background 1.1 General notation and abbreviations 1.2 ‘Power’ vocabulary 1.3 Some ‘Bayesian’ concepts", " Frequentist, Bayesian and hybrid approaches for sample size and power calculations André Moser, CTU Bern, University of Bern 2023-04-07 Chapter 1 Background The terminology of ‘power’ is often imprecisely used [1]. Kunzmann et al. suggest to use the neutral term ‘probability of rejection’. The classical (frequentist) ‘power’ is defined as the probability of rejection given that the alternative hypothesis is true. Yet, frequentist power calculations do not include uncertainties of the treatment effect. Bayesian and hybrid approaches include such uncertainties in their calculations. The following manuscript uses the different approaches (frequentist, Bayesian and hybrid) for the calculation of ‘the probability of rejection’. Definition ‘hybrid’ ([2], Section 6.5.2) ‘[…] we have a prior distribution to use in our study design, but that the conclusions of the study will be entirely classical and will not make use of the prior […]’ 1.1 General notation and abbreviations iid: independent and identically distributed pdf: probability density function \\(\\phi\\): Probability density function of the standard Gaussian distribution \\(\\Phi\\): Cumulative distribution function of the standard Gaussian distribution \\(\\Phi^{-1}\\): Quantile function of the standard Gaussian distribution function 1.2 ‘Power’ vocabulary Frequentist power: Probability of rejection under the alternative hypothesis. Average power: Prior averaged probability of rejection. Often also called ‘probability of success’, ‘assurance’, ‘Bayesian predictive power’. Expected power: 1.3 Some ‘Bayesian’ concepts Prior predictive distribution: Situation before a sample was taken. Let \\(\\theta\\) be a realisation of a random variable \\(\\Theta\\) with pdf \\(p(\\theta)\\). Then for a future observation \\(\\tilde X\\) \\[ p(\\tilde x)=\\int_\\Theta p(\\tilde x, \\theta)d\\theta=\\int_\\Theta \\underbrace{p(\\tilde x | \\theta)}_{likelihood}\\underbrace{p(\\theta)}_{prior}d\\theta \\] Posterior predictive distribution: Situation after a sample was taken. Let \\(\\theta\\) be a realisation of a random variable \\(\\Theta\\) with pdf \\(p(\\theta)\\). Then for a future observation \\(\\tilde X\\) and observed \\(X\\) \\[ p(\\tilde x|x)=\\int_\\Theta p(\\tilde x | \\theta, x)p(\\theta|x)d\\theta=\\int_\\Theta \\underbrace{p(\\tilde x | \\theta)}_{likelihood}\\underbrace{p(\\theta|x)}_{prior}d\\theta, \\] since \\(X\\) is independent \\(\\tilde X\\). References "],["two-arm-non-inferiority-setting.html", "Chapter 2 Two-arm non-inferiority setting 2.1 Binomial outcome", " Chapter 2 Two-arm non-inferiority setting In this section we consider a non-inferiority clinical trial setting with a null hypothesis \\(H_0: \\delta &gt; \\delta^*\\) and alternative hypothesis \\(H_a: \\delta \\leq \\delta^*\\), where \\(\\delta^*&gt;0\\) is a fixed non-inferiority margin and a treatment effect \\(\\delta\\). 2.1 Binomial outcome Here \\(p_i\\), \\(i\\in \\{0,1\\}\\), are event probabilities from two treatment arms. \\(\\delta=p_1-p_0\\) is the true treatment effect expressed as a risk difference. Working example We use the SAFE-SSPE trial as a working example [3]. In brief, this non-inferiority randomised placebo-controlled trial compares clinical surveillance versus anticoagulant treatment in low-risk patients with isolated subsegmental pulmonary embolism (SSPE). The primary outcome is 3-month recurrence of venous thromboembolism (VTE). The null hypothesis \\(H_0\\) is ‘clinical surveillance is inferior to anticoagulant treatment’ versus the alternative hypothesis \\(H_a\\) ‘clinical surveillance is non-inferior to anticoagulant treatment’. The non-inferiority margin was set at 3.5% and it was assumed that the proportion of VTE in both groups was 1%. 2.1.1 Frequentist approach Let \\(Y_{i,k} \\sim^{iid} Bernoulli(p_i)\\), \\(k=1,\\dots,n_i\\), \\(i\\in \\{0,1\\}\\). Let \\(\\overline p_i=\\frac{1}{n_i}\\sum_{k\\leq n_i} Y_{i,k}\\), \\(i\\in {0,1}\\), and thus the estimated risk difference \\(D=\\overline p_1-\\overline p_0\\) is Gaussian distributed with \\(D \\sim N\\left(\\delta, \\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_0^2}{n_0}\\right)\\), where \\(\\sigma_i^2=p_i(1-p_i)\\), \\(i\\in \\{0,1\\}\\). For notational purposes we denote \\(\\sigma_{treat}^2=\\frac{\\sigma_1^2}{n_1}+\\frac{\\sigma_0^2}{n_0}\\), that is, the variance for the estimated treatment effect. We are interested whether the upper \\((1-\\alpha)\\%\\)-confidence limit is smaller than the non-inferiority margin, that is, \\[ D+z_{1-\\alpha}\\sqrt{\\frac{n_0\\sigma_1^2+n_1\\sigma_0^2}{n_1n_0}}\\leq \\delta^*, \\] where \\(z_{1-\\alpha}=\\Phi^{-1}(1-\\alpha)\\). Simple algebra leads to \\[ D\\leq -z_{1-\\alpha}\\sqrt{\\frac{n_0\\sigma_1^2+n_1\\sigma_0^2}{n_1n_0}}+\\delta^*. \\] Note that \\(D_{suc}^{\\delta^*}:=-z_{1-\\alpha}\\sqrt{\\frac{n_0\\sigma_1^2+n_1\\sigma_0^2}{n_1n_0}}+\\delta^*\\) is the required risk difference for a ‘successful’ rejection of the null hypothesis. Then \\[ \\begin{aligned} P_\\delta(D\\leq D_{suc}^{\\delta^*})&amp;=\\Phi\\left(-z_{1-\\alpha}-\\sqrt{\\frac{n_1n_0}{n_0\\sigma_1^2+n_1\\sigma_0^2}}(\\delta-\\delta^*)\\right) \\\\ &amp;=\\Phi\\left(-z_{1-\\alpha}-\\frac{\\delta-\\delta^*}{\\sigma_{treat}}\\right), \\end{aligned} \\] since under regularity conditions, \\[ Z=\\frac{D-\\delta^*}{\\sigma_{treat}} \\rightarrow N(0,1), \\quad \\min(n_1,n_0) \\rightarrow \\infty. \\] \\(P_{\\delta}(D\\leq D_{suc}^{\\delta^*})\\) is the ‘probability of rejection given \\(\\delta\\)’. Under the null value \\(\\delta_0=p_1-p_0\\), \\(P_{\\delta_0}(D\\leq D_{suc}^{\\delta^*})=\\alpha\\) is the ‘type-I error’ and under an alternative value \\(\\delta_A\\), \\(P_{\\delta_A}(D\\leq D_{suc}^{\\delta^*})=1-\\beta\\) is the ‘frequentist power’. For an alternative value \\(\\delta_A\\) it holds that \\[ -z_{1-\\alpha}-\\sqrt{\\frac{n_1n_0}{n_0\\sigma_1^2+n_1\\sigma_0^2}}(\\delta_A-\\delta^*)=\\Phi^{-1}(1-\\beta)=z_{1-\\beta} \\] and so the sample size can then be derived as \\[ \\frac{(z_{1-\\beta}+z_{1-\\alpha})^2}{(\\delta_A-\\delta^*)^2}=\\frac{an_0^2}{n_0\\sigma_1^2+an_0\\sigma_0^2}, \\] where \\(a=n_1/n_0\\) is an allocation ratio, such that \\[ n_0=(z_{1-\\beta}+z_{1-\\alpha})^2\\frac{\\sigma_1^2+a\\sigma_0^2}{a(\\delta_A-\\delta^*)^2}, \\quad n_1=an_0. \\] \\(\\delta_0\\), \\(\\delta_A\\) and \\(\\delta^*\\) are assumed as fixed and known constants in a frequentist approach. Their choices are of high importance, because all trial conclusions are based on those choices and affect the sample size calculation. The plot below shows how the sample size increase as \\(\\delta^*\\) approaches \\(\\delta\\). Working example (continued) We calculate the required sample size for the SAFE-SSPE trial under the following parameters: \\(p_1=0.01\\), \\(p_0=0.01\\), \\(\\delta^*=0.035\\), \\(1-\\beta=0.8\\), \\(\\alpha=0.05\\), \\(a=1/1\\) library(epiR) alpha &lt;- 0.05 beta &lt;- 0.2 p_0 &lt;- 0.01 p_1 &lt;- 0.01 delta &lt;- p_1-p_0 delta_star &lt;- 0.035 sd_0 &lt;- sqrt(p_0*(1-p_0)) sd_1 &lt;- sqrt(p_1*(1-p_1)) a &lt;- 1/1 epi.ssninfb(treat=p_1, control=p_0, delta=delta_star, power=1-beta, r=a, alpha=alpha, n=NA) ## $n.total ## [1] 200 ## ## $n.treat ## [1] 100 ## ## $n.control ## [1] 100 ## ## $delta ## [1] 0.035 ## ## $power ## [1] 0.8 n_0 &lt;- ((qnorm(1-beta)+qnorm(1-alpha))^2)*((sd_1^2+a*sd_0^2)/(a*(delta-delta_star)^2)) n_0 ## [1] 99.93031 n_1 &lt;- n_0*a n_1 ## [1] 99.93031 Given the specified operating characteristics and parameters a sample size of 200 patients (100 per arm) is needed to reject the null hypothesis of inferiority. This is more or less the sample size mentioned in the study protocol of the SAFE-SSPE trial but without dropouts and adjustments for rare events. 2.1.2 Hybrid approach: Prior on treatment effect Suppose that the true treatment effect \\(\\delta\\) is a realization from a random variable \\(\\Delta\\) with \\(p(\\delta)\\). In this subsection we assume that the prior comes from a Gaussian distribution function so that \\(\\Delta \\sim N\\left(d, \\frac{\\sigma_1^2+\\sigma_0^2}{m}\\right)\\). Note that this prior can be thought as a realisation from \\(m\\) Gaussian ‘prior observations’ with variance \\(\\sigma_1^2+\\sigma_0^2\\). Again for notational purposes we denote \\(\\sigma_{prior}^2=\\frac{\\sigma_1^2+\\sigma_0^2}{m}\\) as the variance of the design prior on the treatment effect. In the following we will use the following priors: Enthusiastic prior (favors non-inferiority): \\(d=0\\), \\(m=6.6\\), \\(P(\\Delta&gt;\\delta^*)=0.05\\). This prior is centered on the treatment effect such that there is a low probability (here 5%) of inferiority. Skeptical prior (favors inferiority): \\(d=\\delta^*\\), \\(m=6.6\\), \\(P(\\Delta&gt;0)=0.05\\). This prior is centered on the non-inferiority margin such that there is a low probability (here 5%) of superiority. Informative prior (clinical expert knowledge): \\(d=0\\) with \\(m=25\\). Noninformative prior: \\(d=0\\) with \\(m=0.5\\). Let \\[ AP:=\\int_{\\Delta} P_{\\delta}(D\\leq D_{suc}^{\\delta^*})p(\\delta)d\\delta, \\] be the ‘average power’ [4] (also called ‘assurance’ [5], ‘probability of success’ [1], [2] or Bayesian predictive power [6]. The supplemental section of [1] contains a literature review of the used terminology). Remember that in an hybrid approach we are interested in trial conclusions from a frequentist point of view, thus we are interested in \\[ D\\leq -z_{1-\\alpha}\\sqrt{\\frac{n_0\\sigma_1^2+n_1\\sigma_0^2}{n_1n_0}}+\\delta^*. \\] By using a design prior we take into account the uncertainty of the treatment effect. The prior predictive distribution for an estimated risk difference, say \\(\\tilde D\\), with a prior \\(\\Delta \\sim N\\left(d, \\sigma_{prior}^2\\right)\\) includes this uncertainty. For the Gaussian case, the prior predictive distribution of \\(\\tilde D\\) is given as \\[ \\tilde D \\sim N\\left(d, \\sigma_{treat}^2+\\sigma_{prior}^2\\right) \\], since \\(\\tilde D \\sim N\\left(\\delta, \\sigma_{treat}^2\\right)\\). Suppose now that \\(D\\) has a predictive distribution as described above, then \\[ \\begin{aligned} AP&amp;=\\int_{-\\infty}^{-z_{1-\\alpha}\\sqrt{\\frac{n_0\\sigma_1^2+n_1\\sigma_0^2}{n_1n_0}}+\\delta^*}f(\\tilde\\delta)d\\tilde\\delta\\\\ &amp;= \\Phi\\left(-z_{1-\\alpha}\\sqrt{\\frac{n_0\\sigma_1^2+n_1\\sigma_0^2}{n_0\\sigma_1^2c_1+n_1\\sigma_0^2c_0}}-\\sqrt{\\frac{n_1n_0}{n_0\\sigma_1^2c_1+n_1\\sigma_0^2c_0}}(d-\\delta^*)\\right)\\\\ &amp;=\\Phi\\left(\\sqrt{\\frac{n_0\\sigma_1^2+n_1\\sigma_0^2}{n_0\\sigma_1^2c_1+n_1\\sigma_0^2c_0}}\\left[-z_{1-\\alpha}-\\sqrt{\\frac{n_1n_0}{n_0\\sigma_1^2+n_1\\sigma_0^2}}(d-\\delta^*)\\right]\\right), \\end{aligned} \\] see for example [4]. Note that as \\(m \\rightarrow \\infty\\), then \\(c_i \\rightarrow 1\\), \\(i\\in {0,1}\\), and \\(AP \\rightarrow \\Phi\\left(-z_{1-\\alpha}-\\frac{d-\\delta^*}{\\sigma_{treat}}\\right)\\), that is, the frequentist power at \\(d\\). Working example (continued) We calculate the AP under the assumed prior distributions and parameters for the SAFE-SSPE trial. # Enthusiastic prior m &lt;- 6.6 c_1 &lt;- (m+n_1)/m c_0 &lt;- (m+n_0)/m prior_mean &lt;- 0 AP &lt;- pnorm(-qnorm(1-alpha)*sqrt(n_0*sd_1^2+n_1*sd_0^2)/sqrt(n_0*sd_1^2*c_1+n_1*sd_0^2*c_0)-(sqrt(n_0*n_1)/sqrt(n_0*sd_1^2*c_1+n_1*sd_0^2*c_0))*(prior_mean-delta_star)) data_output &lt;- data.frame(type=&quot;Enthusiastic&quot;, n_0, n_1, AP=round(AP,2)) # Skeptical prior m &lt;- 6.6 c_1 &lt;- (m+n_1)/m c_0 &lt;- (m+n_0)/m prior_mean &lt;- delta_star AP &lt;- pnorm(-qnorm(1-alpha)*sqrt(n_0*sd_1^2+n_1*sd_0^2)/sqrt(n_0*sd_1^2*c_1+n_1*sd_0^2*c_0)-(sqrt(n_0*n_1)/sqrt(n_0*sd_1^2*c_1+n_1*sd_0^2*c_0))*(prior_mean-delta_star)) data_output &lt;- rbind(data_output, data.frame(type=&quot;Skeptical&quot;, n_0, n_1, AP=round(AP,2))) # Informative prior m &lt;- 25 c_1 &lt;- (m+n_1)/m c_0 &lt;- (m+n_0)/m prior_mean &lt;- 0 AP &lt;- pnorm(-qnorm(1-alpha)*sqrt(n_0*sd_1^2+n_1*sd_0^2)/sqrt(n_0*sd_1^2*c_1+n_1*sd_0^2*c_0)-(sqrt(n_0*n_1)/sqrt(n_0*sd_1^2*c_1+n_1*sd_0^2*c_0))*(prior_mean-delta_star)) data_output &lt;- rbind(data_output, data.frame(type=&quot;Informative&quot;, n_0, n_1, AP=round(AP,2))) # Noninformative prior m &lt;- 0.5 c_1 &lt;- (m+n_1)/m c_0 &lt;- (m+n_0)/m prior_mean &lt;- 0 AP &lt;- pnorm(-qnorm(1-alpha)*sqrt(n_0*sd_1^2+n_1*sd_0^2)/sqrt(n_0*sd_1^2*c_1+n_1*sd_0^2*c_0)-(sqrt(n_0*n_1)/sqrt(n_0*sd_1^2*c_1+n_1*sd_0^2*c_0))*(prior_mean-delta_star)) data_output &lt;- rbind(data_output, data.frame(type=&quot;Noninformative&quot;, n_0, n_1, AP=round(AP,2))) data.frame(data_output %&gt;% arrange(type)) ## type n_0 n_1 AP ## 1 Enthusiastic 99.93031 99.93031 0.58 ## 2 Informative 99.93031 99.93031 0.65 ## 3 Noninformative 99.93031 99.93031 0.52 ## 4 Skeptical 99.93031 99.93031 0.34 Under an ‘enthusiastic prior’ we get an average power of 58%. For an ‘skeptical prior’ the average power decreases to 34%. These values are lower than the frequentist power of 80%. Rufibach et al. give a closed a formula for the distribution of \\(RPR:=P_\\Delta(D\\leq D_{suc}^{\\delta^*})\\), where \\(\\Delta \\sim N(d,\\sigma^2_{prior})\\), and discuss the shape under different prior choices [6]. In the following we use the wording ’random probability to reject` (RPR) similar to [1]. For \\(0&lt;y&lt;1\\), the random variable \\(RPR\\) has a probability density function \\[ \\begin{aligned} f(y)&amp;=\\frac{\\sigma_{treat}}{\\sigma_{prior}} \\phi\\left(-z_{1-\\alpha}\\frac{\\sigma_{treat}}{\\sigma_{prior}}-\\frac{d-\\delta^*}{\\sigma_{prior}}-\\frac{\\sigma_{treat}}{\\sigma_{prior}}\\Phi^{-1}(y) \\right)\\left[ \\phi\\left(\\Phi^{-1}(y) \\right) \\right]^{-1}, \\end{aligned} \\] see [6]. Special case For the case that \\(n_0=n_1=n\\) and \\(\\sigma_1^2=\\sigma_0^2=\\sigma^2\\), then \\(\\sigma_{treat}^2=\\frac{2\\sigma^2}{n}\\) and \\(\\sigma_{prior}^2=\\frac{2\\sigma^2}{m}\\), and the formula above reduces to \\[ \\begin{aligned} f(y)&amp;=\\sqrt{\\frac{m}{n}}\\left[ \\phi\\left(\\Phi^{-1}(y) \\right) \\right]^{-1}\\phi\\left(\\sqrt{\\frac{m}{n}}\\left[-z_{1-\\alpha}-\\sqrt{\\frac{n}{2\\sigma^2}}(d-\\delta^*)-\\Phi^{-1}(y)\\right] \\right), \\quad 0&lt;y&lt;1. \\end{aligned} \\] Working example (continued) We derive the probability densities for the different assumed priors for the SAFE-SSPE study. x &lt;- seq(0.001,0.999,0.001) # Enthusiastic prior m &lt;- 6.6 prior_mean &lt;- 0 ## Rufibach 2016: formula (4) y &lt;- sqrt(m*n_0*sd_1^2+m*n_1*sd_0^2)/(sqrt(n_1*n_0*(sd_0^2+sd_1^2)))*dnorm(-sqrt(m*n_0*sd_1^2+m*n_1*sd_0^2)/(sqrt(n_1*n_0*(sd_0^2+sd_1^2)))*qnorm(1-alpha)-sqrt(m)/sqrt((sd_0^2+sd_1^2))*(prior_mean-delta_star)-sqrt(m*n_0*sd_1^2+m*n_1*sd_0^2)/(sqrt(n_1*n_0*(sd_0^2+sd_1^2)))*qnorm(x))*(dnorm(qnorm(x)))^(-1) data_power &lt;- data.frame(x, y, type=&quot;Enthusiastic&quot;) # Skeptical prior m &lt;- 6.6 prior_mean &lt;- delta_star y &lt;- sqrt(m*n_0*sd_1^2+m*n_1*sd_0^2)/(sqrt(n_1*n_0*(sd_0^2+sd_1^2)))*dnorm(-sqrt(m*n_0*sd_1^2+m*n_1*sd_0^2)/(sqrt(n_1*n_0*(sd_0^2+sd_1^2)))*qnorm(1-alpha)-sqrt(m)/sqrt((sd_0^2+sd_1^2))*(prior_mean-delta_star)-sqrt(m*n_0*sd_1^2+m*n_1*sd_0^2)/(sqrt(n_1*n_0*(sd_0^2+sd_1^2)))*qnorm(x))*(dnorm(qnorm(x)))^(-1) data_power &lt;- rbind(data_power, data.frame(x, y, type=&quot;Skeptical&quot;)) # Informative prior m &lt;- 25 prior_mean &lt;- 0 y &lt;- sqrt(m*n_0*sd_1^2+m*n_1*sd_0^2)/(sqrt(n_1*n_0*(sd_0^2+sd_1^2)))*dnorm(-sqrt(m*n_0*sd_1^2+m*n_1*sd_0^2)/(sqrt(n_1*n_0*(sd_0^2+sd_1^2)))*qnorm(1-alpha)-sqrt(m)/sqrt((sd_0^2+sd_1^2))*(prior_mean-delta_star)-sqrt(m*n_0*sd_1^2+m*n_1*sd_0^2)/(sqrt(n_1*n_0*(sd_0^2+sd_1^2)))*qnorm(x))*(dnorm(qnorm(x)))^(-1) data_power &lt;- rbind(data_power, data.frame(x, y, type=&quot;Informative&quot;)) # Noninformative prior m &lt;- 0.5 prior_mean &lt;- 0 y &lt;- sqrt(m*n_0*sd_1^2+m*n_1*sd_0^2)/(sqrt(n_1*n_0*(sd_0^2+sd_1^2)))*dnorm(-sqrt(m*n_0*sd_1^2+m*n_1*sd_0^2)/(sqrt(n_1*n_0*(sd_0^2+sd_1^2)))*qnorm(1-alpha)-sqrt(m)/sqrt((sd_0^2+sd_1^2))*(prior_mean-delta_star)-sqrt(m*n_0*sd_1^2+m*n_1*sd_0^2)/(sqrt(n_1*n_0*(sd_0^2+sd_1^2)))*qnorm(x))*(dnorm(qnorm(x)))^(-1) data_power &lt;- rbind(data_power, data.frame(x, y, type=&quot;Noninformative&quot;)) data_output2 &lt;- data_output %&gt;% select(type, x=AP) %&gt;% mutate(y=0) ggplot(data_power, aes(x, y, colour=type))+geom_line(linewidth=1)+geom_point(data=data_output2, aes(x=x, y=y, colour=type))+scale_colour_manual(&quot;Prior type&quot;, values=c(&quot;purple&quot;, &quot;orange&quot;, &quot;blue&quot;, &quot;darkred&quot;))+theme_bw()+theme(panel.grid = element_blank())+ylab(&quot;Density&quot;)+xlab(&quot;RPR&quot;)+ylim(c(0,2))+labs(caption=&quot;Dots indicate the AP.&quot;) The cumulative distribution function of \\(RPR\\) can the be calculated as \\[ \\begin{aligned} P(RPR\\leq y)=1-\\Phi&amp;\\left(-z_{1-\\alpha}\\frac{\\sigma_{treat}}{\\sigma_{prior}}-\\frac{d-\\delta^*}{\\sigma_{prior}}-\\frac{\\sigma_{treat}}{\\sigma_{prior}}\\Phi^{-1}(y) \\right), \\quad 0&lt;y&lt;1. \\end{aligned} \\] Special case For the case that \\(n_0=n_1=n\\) and \\(\\sigma_1^2=\\sigma_0^2=\\sigma^2\\), then \\(\\sigma_{treat}^2=\\frac{2\\sigma^2}{n}\\) and \\(\\sigma_{prior}^2=\\frac{2\\sigma^2}{m}\\), and the formula above reduces to \\[ \\begin{aligned} P(RPR\\leq y)=1-\\Phi&amp;\\left(\\sqrt{\\frac{m}{n}}\\left[-z_{1-\\alpha}-\\sqrt{\\frac{n}{2\\sigma^2}}(d-\\delta^*)-\\Phi^{-1}(y)\\right] \\right), \\quad 0&lt;y&lt;1. \\end{aligned} \\] This allows the calculation of probability statements that the probability of the random probability of rejection is greater than a threshold, say \\(0&lt;\\gamma&lt;1\\), that is \\(P(RPR&gt;\\gamma)\\): For a specific threshold \\(\\gamma=0.6\\) we obtain Note that the average power AP integrates over the whole \\(\\Delta\\) range. This might include also ‘non-favorable’ regions. To see that one can decompose AP as follows (see [1], [4]): \\[ AP=\\overbrace{P(D\\leq D_{suc}^{\\delta^*}, \\Delta&gt;\\delta^*)}^{(1)}+\\overbrace{P(D\\leq D_{suc}^{\\delta^*}, 0&lt;\\Delta\\leq\\delta^*)}^{(2)}+\\overbrace{P(D\\leq D_{suc}^{\\delta^*}, \\Delta\\leq0)}^{(3)} \\] where Probability of Type-I error, ‘Non-inferior, but treatment effect not relevant’, ‘Non-inferior, treatment effect relevant’. [2] highlights that \\(AP \\approx P(D\\leq D_{suc}^{\\delta^*}, \\Delta\\leq0)\\) because the type-I error is often small and one has strong believe for the alternative hypothesis. [1] and [5] discuss the relevance of the AP decomposition. For example, pharmaceutical companies might (1)+(2)+(3) taking into account shortterm risk, wheras regulators are interested in (1) or (1)+(2), that is non-inferior outcomes with relevant treatment effects. The AP decomposition can be visualised using the posterior predictive distribution. Let \\(p(\\tilde\\delta)\\) be the pdf of the posterior predictive distribution then \\[ p(\\tilde\\delta, \\delta) \\] Under enthusiastic prior: ## region prop ## 1 &#39;Not significant&#39; 0.4168 ## 2 (3) 0.4851 ## 3 (2) 0.0964 ## 4 (1) 0.0017 \\[ AP=\\overbrace{P(D\\leq D_{suc}^{\\delta^*}, \\Delta&gt;\\delta^*)}^{(1)}+\\overbrace{P(D\\leq D_{suc}^{\\delta^*}, 0&lt;\\Delta\\leq\\delta^*)}^{(2)} \\\\ +\\overbrace{P(D\\leq D_{suc}^{\\delta^*}, \\Delta\\leq0)}^{(3)} \\] For our noninferiority setting consider (2)+(3). \\[ P(D\\leq D_{suc}^{\\delta^*}, \\Delta\\leq\\delta^*)=P(D\\leq D_{suc}^{\\delta^*}|\\Delta\\leq\\delta^*)P(\\Delta\\leq\\delta^*)\\\\=\\underbrace{E\\left[P_{\\Delta\\leq\\delta^*}(D\\leq D_{suc}^{\\delta^*})\\right]}_{EP}P(\\Delta\\leq\\delta^*), \\] where \\(EP\\) is ‘expected power’ (Kunzmann et al.). Spiegelhalter calls \\(P(Z\\leq - z_{1-\\alpha}, \\Delta\\leq\\delta^*)\\) the ‘prior adjusted power’ (PAP): \\[ \\underbrace{P(D\\leq D_{suc}^{\\delta^*}, \\Delta\\leq\\delta^*)}_{PAP}=\\underbrace{E\\left[P_{\\Delta\\leq\\delta^*}(D\\leq D_{suc}^{\\delta^*})\\right]}_{EP}\\underbrace{P(\\Delta\\leq\\delta^*)}_{constant} \\] Noninferiority setting \\(\\Delta\\leq\\delta^*\\): ## ep pap ap const type ## 1 0.7930 0.5857 0.5872 0.7386 Skeptical ## 2 0.6741 0.3370 0.3437 0.5000 Enthusiastic ## 3 0.7931 0.5858 0.5872 0.7386 Informative ## 4 0.9186 0.6785 0.5233 0.7386 Noninformative 2.1.3 Proper Bayesian approach A proper Bayesian approach uses the posterior distribution to define ‘Bayesian significance’: \\(S^B:=P(\\Delta\\leq\\delta^*|data)=1-\\epsilon\\). Remember \\(D=p_1-p_0\\) with \\(D \\sim N(\\delta, \\sigma^2_{treat})\\). Suppose that \\(\\Delta \\sim N(d, \\sigma^2_{prior})\\) then the posterior distribution given \\(D\\) is distributed as \\[ \\begin{aligned} \\Delta|D \\sim N\\left(\\frac{\\frac{d}{\\sigma^2_{prior}}+\\frac{D}{\\sigma^2_{treat}}}{\\frac{1}{\\sigma^2_{prior}}+\\frac{1}{\\sigma^2_{treat}}}, \\frac{1}{\\frac{1}{\\sigma^2_{prior}}+\\frac{1}{\\sigma^2_{treat}}}\\right)=N\\left( \\frac{\\sigma^2_{treat}d+\\sigma^2_{prior}D}{\\sigma^2_{treat}+\\sigma^2_{prior}}, \\frac{\\sigma^2_{treat}\\sigma^2_{prior}}{\\sigma^2_{treat}+\\sigma^2_{prior}} \\right) \\end{aligned} \\] Special case If \\(n_0=n_1=n\\) and \\(\\sigma_1^2=\\sigma_0^2=\\sigma^2\\), then \\(\\sigma_{treat}^2=\\frac{2\\sigma^2}{n}\\) and \\(\\sigma_{prior}^2=\\frac{2\\sigma^2}{m}\\), and the formula above reduces to \\[ \\Delta|D \\sim N\\left(\\frac{m\\delta+nD}{n+m}, \\frac{\\sigma^2}{n+m} \\right). \\] Bases on the above specified ‘Bayesian significance’ we are interested whether the upper \\((1-\\epsilon)\\) credible interval is smaller than the non-inferiority margin, that is \\[ \\frac{\\sigma^2_{treat}d+\\sigma^2_{prior}D}{\\sigma^2_{treat}+\\sigma^2_{prior}}+z_{1-\\epsilon}\\frac{\\sigma_{treat}\\sigma_{prior}}{\\sqrt{\\sigma^2_{treat}+\\sigma^2_{prior}}}\\leq \\delta^*. \\] A simple algebraic step gives \\[ \\begin{aligned} D\\leq -z_{1-\\epsilon}&amp;\\frac{\\sigma_{treat}}{\\sigma_{prior}}\\sqrt{\\sigma^2_{treat}+\\sigma^2_{prior}}+\\delta^*\\left(1+\\frac{\\sigma_{treat}^2}{\\sigma_{prior}^2}\\right)-\\frac{\\sigma^2_{treat}}{\\sigma^2_{prior}}d \\end{aligned} \\] \\(D_{suc}^{d,\\delta^*}=-z_{1-\\epsilon}&amp;\\frac{\\sigma_{treat}}{\\sigma_{prior}}\\sqrt{\\sigma^2_{treat}+\\sigma^2_{prior}}+\\delta^*\\left(1+\\frac{\\sigma_{treat}^2}{\\sigma_{prior}^2}\\right)-\\frac{\\sigma^2_{treat}}{\\sigma^2_{prior}}d\\) can be seen as a success rejection of the null hypothesis in the Bayesian setting. Thus \\[ \\begin{aligned} P(S^B|\\delta)&amp;=\\Phi\\left(-z_{1-\\epsilon}\\sqrt{1+\\frac{\\sigma^2_{treat}}{\\sigma_{prior}^2}}-\\frac{1}{\\sigma_{treat}}\\left[\\delta-\\delta^*\\left\\{ 1+\\frac{\\sigma_{treat}^2}{\\sigma_{prior}^2} \\right\\} \\right]-\\frac{\\sigma_{treat}}{\\sigma_{prior}^2}d \\right) \\end{aligned} \\] Special case If \\(n_0=n_1=n\\) and \\(\\sigma_1^2=\\sigma_0^2=\\sigma^2\\), then \\(\\sigma_{treat}^2=\\frac{2\\sigma^2}{n}\\) and \\(\\sigma_{prior}^2=\\frac{2\\sigma^2}{m}\\), and the formula above reduces to \\[ \\begin{aligned} P(S^B|\\delta)&amp;=\\Phi\\left(-z_{1-\\epsilon}\\sqrt{\\frac{n+m}{n}}- \\frac{m}{\\sqrt{2n\\sigma^2}}d-\\sqrt{\\frac{n}{2n\\sigma^2}}\\left\\{\\delta-\\delta^*\\left(\\frac{n+m}{n} \\right)\\right\\} \\right). \\end{aligned} \\] ## delta y type ## 1 0.000 0.83 Bayes: Enthusiastic ## 2 0.035 0.06 Bayes: Enthusiastic ## 3 0.000 0.78 Bayes: Skeptical ## 4 0.035 0.04 Bayes: Skeptical ## 5 0.000 0.90 Bayes: Informative ## 6 0.035 0.11 Bayes: Informative ## 7 0.000 0.80 Bayes: Noninformative ## 8 0.035 0.05 Bayes: Noninformative ## 9 0.000 0.80 Frequentist ## 10 0.035 0.05 Frequentist The average Bayesian power can be calculated as $$ $$ \\(P(S^B)=\\Phi\\left(-\\sqrt{\\frac{n_0}{n}}z_{1-\\epsilon}-\\frac{\\sqrt{n_0}\\sqrt{n_0+n}(d-\\delta^*)}{\\sqrt{n}\\tilde\\sigma }\\right)\\) ## type AP AP_bayes ## 1 Enthusiastic 0.583 0.594 ## 2 Skeptical 0.341 0.336 ## 3 Informative 0.647 0.715 ## 4 Noninformative 0.524 0.524 References "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
